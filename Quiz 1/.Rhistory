install.packages("KernSmooth")
library(KernSmooth)
remove.packages("KernSMooth")
remove.packages("KernSmooth")
above <- function(x, n=10) {
use <- x > n
x[use]
}
above(4)
x <- 1:20
above(x)
above(x, 12)
clear
ls
clear()
x <- 1:10
if(x>5) x<- 0
f <- function(x) {
g <- function(y) {
y + z
}
z <- 4
x + g(x)
}
z <- 10
f(3)
f <- function(x) {
g <- function(y) {
y + z
}
z <- 4
x + g(x)
}
z <- 10
f(3)
library(datasets)
data(iris)
head(iris)
head(iris[which(iris$Species="virginica"), ])
head(iris[which(iris$Species=="virginica"), ])
a = iris[which(iris$Species=="virginica"), ]
mean(a$Sepal.Length)
apply(iris[, 1:4], 2, mean)
data(mtcars)
head(mtcars)
with(mtcars, tapply(mpg, cyl, mean))
set.seed(1)
rpois(5,2)
set.seed(10)
x = rep(0:1, each=5)
e = rnorm(10,0,20)
y = 0.5 + 2 * x + e
class(xyplot())
library(lattice)
library(datasets)
class(xyplot(Ozone ~ Wind, data = airquality))
library(nlme)
xyplot(weight ~ Time | Diet, BodyWeight)
?lpoints
?points
?text
?lines
data(airquality)
swirl()
library(swirl)
swirl()
library(dplyr)
cran <- tbl_df()
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran)
group_by(cran, package)
group_by(cran, by_package)
by_package <- group_by(cran, package)
by_package
summarize(by_package, mean(size))
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pack_sum, count>679)
top_counts
View(top_counts)
?arrange
top_counts_sorted <- arrange(top_counts, count)
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique > 465)
View(top_unique)
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
?chain
submit()
View(result3)
submit()
submit()
submit()
?mutate
submit()
submit()
?mutate
submit()
submit()
submit()
library(swirl)
swirl()
library(tidyr)
students
?gather
gather(students, sex, count, -grade)
students2
gather(students2, sex_class, count, -grade)
res <- gather(students2, sex_class, count, -grade)
res
?separate
separate(res, sex_class, into = c("sex", "class"), sep = "_")
separate(res, sex_class, into = c("sex", "class"))
?chain
submit()
students3
?gather
submit()
?spread
submit()
submit()
submit()
submit()
submit()
students3
gather(students3, class, grade, class1:class5, na.rm=TRUE)
submit()
submit()
extract_numeric("class5")
?mutate
?mutate
?mutate
?mutate
?extract_numeric
?mutate
submit()
students4
submit()
submit()
submit()
passed
failed
?mutate
library(dplyr)
passed <- passed %>% mutate(status="passed")
failed <- failed %>% mutate(status="failed")
?bind_rows
packageVersion('dplyr')
bind_rows(passed, failed)
sat
?gather
?separate
submit()
submit()
submit()
library(swirl)
swirl()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package=lubridate)
this_day <- today()
this_day
year(this_day)
wday(this_day)
wday(this_day, label = TRUE)
this_moment = now()
this_moment <- now()
this_moment
hour(this_moment)
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd("19-20-12")
ymd("1920-1-2")
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours=8, minutes=34, seconds=55)
this_moment
this_moment <- update(this_moment, hours=8, minutes=15)
this_moment
?now
now("America/New_York")
nyc <- now("America/New_York")
nyc
depart <- nyc + days(2)
depart
depart <- update(depart, hours=17, minutes=34)
depart
arrive = depart + hours(15) + minutes(50)
?with_tz
arrive <- with_tz(arrive, "Asia/Hong_Kong")
arrive
last_time <- mdy("June 17, 2008", tz="Singapore")
last_time
?new_interval
how_long <- new_interval(last_time, arrive)
as.period(how_long)
stopwatch()
library(dplyr)
?filter
?dplyr
a = read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv")
head(a)
a
names(a)
head(a$ACR)
unique(a$ACR)
unique(a$AGS)
source('~/OneDrive/Coursera/03 - Getting and Cleaning Data/W3 Quiz/quiz3.R')
q1
q1()
?top_n
source('~/OneDrive/Coursera/03 - Getting and Cleaning Data/W3 Quiz/quiz3.R')
q1()
?which
source('~/OneDrive/Coursera/03 - Getting and Cleaning Data/W3 Quiz/quiz3.R')
q1()
source('~/OneDrive/Coursera/03 - Getting and Cleaning Data/W3 Quiz/quiz3.R')
q1()
source('~/OneDrive/Coursera/03 - Getting and Cleaning Data/W3 Quiz/quiz3.R')
q1()
read.jpg
?read.jpg
?read.table
?readJPEG
readJPEG("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg", native=TRUE)
source('~/OneDrive/Coursera/03 - Getting and Cleaning Data/W3 Quiz/quiz3.R')
q2()
source('~/OneDrive/Coursera/03 - Getting and Cleaning Data/W3 Quiz/quiz3.R')
package_install(jpeg)
install.packages("jpeg")
source('~/OneDrive/Coursera/03 - Getting and Cleaning Data/W3 Quiz/quiz3.R')
q2()
?dplyr
source('~/OneDrive/Coursera/03 - Getting and Cleaning Data/W3 Quiz/quiz3.R')
q3()
source('~/OneDrive/Coursera/03 - Getting and Cleaning Data/W3 Quiz/quiz3.R')
library(tidyr)
a
source('~/OneDrive/Coursera/03 - Getting and Cleaning Data/W3 Quiz/quiz3.R')
q3()
source('~/OneDrive/Coursera/03 - Getting and Cleaning Data/W3 Quiz/quiz3.R')
q3()
?read.csv
source('~/OneDrive/Coursera/03 - Getting and Cleaning Data/W3 Quiz/quiz3.R')
q3()
source('~/OneDrive/Coursera/03 - Getting and Cleaning Data/W3 Quiz/quiz3.R')
q3()
?select
source('~/OneDrive/Coursera/03 - Getting and Cleaning Data/W3 Quiz/quiz3.R')
q3()
source('~/OneDrive/Coursera/03 - Getting and Cleaning Data/W3 Quiz/quiz3.R')
q3()
source('~/OneDrive/Coursera/03 - Getting and Cleaning Data/W3 Quiz/quiz3.R')
q3()
source('~/OneDrive/Coursera/03 - Getting and Cleaning Data/W3 Quiz/quiz3.R')
install.packages("yaml")
library(swirl)
swirl()
?swirl
install_from_swirl("Statistical Inference")
swirl()
library(swirl)
swirl()
install_from_swirl("Statistical Inference")
swirl()
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
-5:20
-(5:20)
select(cran, -(X:size))
filter(cran, package=="swirl")
filter(cran, r_version=="3.1.1", country=="US")
?Comparison
filter(cran, r_version=="3.0.2", country=="IN")
filter(cran, r_version<="3.0.2", country=="IN")
filter(cran, country=="US" | country=="IN")
filter(cran, size>100500, r_os=="linux-gnu")
is.na(c(3, 5, NA, 10))
!is.na(c(3,5,NA,10))
filter(cran, !is.na(r_version))
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size+1000)
summarize(cran, avg_bytes = mean(size))
library(swirl)
swirl()
1-(2+1)/36
deck
52
4/52
0
(3*4)/52
11/51 + 2/12 - 2/51
2/12
11/51 + 2/12
info()
2/51
.5*.8*1.6
1-0.64
0.64/(.5*2*1)
mypdf
?integrate
integrate(mypdf(1.6))
integrate(mypdf(), 0, 1.6)
integrate(mypdf, 0, 1.6)
?quantile
quantile((x^2)/4, 50)
0.5
4
2
quantile((x^2)/4, 0.5)
4
nxt()
nxt()
info()
skip()
library(swirl)
swirl()
skip()
skip()
skip()
.001*.997
(1-.985)*(1-.001)
(0.001*0.997)/((0.001*0.997)+(1-0.985)*(1-0.001))
exit()
bye()
swirl()
3.5
expect_dice
dice_high
mean(dice_high)
expect_dice(dice_high)
expect_dice(dice_low)
(edh + edl)/2
integrate(myfunc, 0, 2)
spop
mean(spop)
allsam
apply(allsam, 1, mean)
mean(smeans)
setwd("~/OneDrive/Coursera/07 - Regression Models/DataScience-07-RM/Quiz 1")
?n
